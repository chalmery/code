## 日常开发

### 1 开发中遇到过哪些问题都是如何解决的？

> 1 最多的就是空指针
>
> 2 上线配置漏掉，出现问题
>
> 3 一些中间件，或者什么接口的参数限制问题，比如mq,job等长度有要求
>
> 4 慢sql

## 其他

#### 软件开发都有哪些优化手段

> 1. 代码层面抽象，必要的位置考虑埋点，为以后拓展做准备
> 2. 工具类提取，避免重复代码
> 3. 递归可以优化为循环，降低栈内存空间的占用
> 4. 对于一些接口，适当加缓存，对于默认的些数据做成启动时加载到内存

#### 什么是缓存伪共享，以及缓存失效?

> 现代的cpu速度很快，而内存的速度没有跟上，为了适应这种情况就有了高速缓冲区，高速缓冲区有L1,L2,L3三部分，然后L1，L2是每个核心都有独享部分的，而L3是多核心共享的，然后L3中有很多的缓存行，每行都有64字节，比如核心1存了一个8字节的lang数据a，然后核心而也在这有8字节数据b，然后因为一行64位，就存在一个缓存行了，而如果直接读取的话是直接读一个缓存行，但是因为当比如核心1修改a,就会导致这一个缓存行失效，而核心2就会无法命中缓存，导致效率降低
>
> 解决方法：
>
> 字节填充，不够64填充到64，
>
> JAVA出的一个Contended注解，注解范围是field，可以给类属性加，

#### HTTPS和HTTP的区别

> 1） https协议要申请证书到ca，需要一定经济成本；
>
> 2） http是明文传输，https是加密的安全传输；
>
> 3） 连接的端口不一样，http是80，https是443；
>
> 4）http连接很简单，没有状态；https是ssl加密的传输，身份认证的网络协议，相对http传输比较安全。

## 分布式的概念问题

#### 1、微服务之间怎么调用的

> feign调用，是http方式的，那像dubbo这中的rpc框架，是二进制形式传输的

#### 去中心化和中心化各有什么优缺点和使用场景？

> ‍

#### 分布式开发的网关组件应该有什么能力，如何保证永不宕机？

>  1. 根据URI转发到到子服务的能力
>  2. 转发的uri要更具配置文件，对配置文件与工程进行分离，这样只需要到配置中心修改即可，解耦合
>  3. 配置文件修改后，自动生效，而不是重启网关
>  4. 在此处做权限控制，
>  5. 结合公司情况，适当处理请求头，响应头，js跨域问题
>  6. 对API进行版本管理，对不同版本的URI路由到不同的接口

#### 分布式相对于单体有哪些问题，或者有哪些特别需要注意的点？

> 1. 首先是分布式的拆分问题：基于数据拆分，功能拆分，存储与计算等，存储与计算分离，比如主要是存储的则部署到硬盘比较大的服务器，而计算的CPU好可以。而分离的情况，可以让我们灵活的分配硬件。
> 2. 分布式事务问题： TX-LCN ，TCC，XA，HA
> 3. 接口幂等性问题：A调用B,B没有返回，A则重新调用，要保证A调用B一次或者多次，对B的影响是一样的
> 4. 数据共享问题：redis数据缓存，redis数据不一致问题
> 5. 登陆处理：需要单点登录
> 6. Session如果想使用，就要存储到Redis中，因为是多个JVM，session不是同一个
> 7. 要设计无状态接口：要保证

#### 1 微服务之间调用如何保证幂等性？

> 保证幂等性只要是数据的添加，更新，而查询和删除都是具有幂等性的，删除比如基于主键删除，或者逻辑删除都是执行一次或者多次是一样的，因此具有幂等性
>
> 使用全局唯一ID+唯一索引：使用全局唯一id，适合插入的场景，通过唯一id，然后id字段有唯一约束， 这样通过数据库的约束达到的幂等性
>
> 版本控制：适合修改的场景，在表字段加个版本列，每次需要判断版本号

#### 3 雪花算法

> 雪花算法用来实现去中心化的主键生成，比如在分布式情况下，需要分表的情况，主键自增就存在问题了，而雪花算法优点：整体自增，去中心化，效率高。
>
> 主要分为五个部分：
>
> 0+41位的时间戳+5位机房id+5位的机器id+12位的序列码

#### 4 单点登录怎么做？

> 单点登录：在分布式的情况下，服务的JVM有多个，而用户只需要登陆一次即可实现其他JVM也认可这个身份，这就是单点登录。
>
> 单点登录整体分为中心化和求中心化的方式：
>
> * 中心化：是一种耦合的方式，登录的中心服务，会被所有别的服务请求，那么这样登陆服务的QPS会累加导中心点QPS很高，但是可以对用户进行集中管理。
> * 去中心化：虽然无法对用户提掉线功能，但是无中心，只需要签发一次后就可以通用了。
>
> 中心化：
>
> 1. 使用Redis,每个JVM都往redis写JSESSIONID和Session对象，
> 2. CAS，分为CASserver，CASclient,Server为中心，每个服务都是Cliren
>
> 去中心化：
>
> 使用JWT实现的去中心化，浏览器只需要访问登录服务后，携带token访问任何服务都可以自己识别身份，这样登录的服务的QPS就不是累加了

#### 5 Token的有效期时多少时间？

> 1. token有效期时无操作30分钟就失效，每次请求后签发新的token来续约，缺点是性能低，每次请求都要执行运算
> 2. 分布式情况使用网关，在此处校验token,通过 `redis`来存储，存取来校验，这样出现了新的问题，也是中心化的方式
> 3. 双token方式，这样对前端的操作会多些，

#### 线程个数一般设置多少个？

> cpu密集型
>
> 线程个数设置为cpu核心数，因为CPU一直在使用，因此只需要核心数就可以了。
>
> IO密集型
>
> 因为大量做IO操作，导致CPU空闲，通常开CPU核心数的两倍，当线程IO操作时候，其余线程依然使用CPU，提高CPU使用率
>
> （线程等待时间+线程CPU时间)/线程CPU时间*CPU数目

#### 1 不通过构造函数可以创建对象吗？

> 可以的，通过反射或者反序列化就可以拿到一个对象

#### 2 方法重载可以根据方法返回值来区分吗？

> 不可以，如果这两个方法，除了返回值不一样，参数，名称都一样的话，调用这个方法，编译器是懵逼的，因为这两个方法

#### 3 常见http请求响应码

> * **200：请求成功，请求方法为get或post或head或者trace。**
>
> **　　201：请求成功并创建一个资源，请求方法为post或put。**
>
> **　　202：请求收到但未响应。**
>
> **　　204：服务成功处理了请求但是不返回实体内容。**
>
> **　　205：服务成功处理了请求但是不返回实体内容且要求请求者重置请求视图。**
>
> **　　207：返回消息体为XML。**
>
> * **400：语义错误，服务器无法理解此次请求。无效请求，服务器还没接到该请求，由于前端封装的字段类型有误导致。**
> * **401：当前请求需要验证， 即需要类似Authorization 头信息。**
>
> **　　403：服务理解请求但是拒绝执行。通常是无权限、黑名单、ip过于频繁访问等原因导致。**
>
> * **404：请求失败，请求资源找不到。类似于脚本未被定义.**
>
> **　　405：请求方法不被接受，比如某个接口只能用post请求，但是用了get请求，则会报405。**
>
> **　　407：当前请求需要验证，代理服务器必须以Proxy-Authorization 信息头验证。**
>
> **　　408：请求超时。表示客户端取消了请求或未能发送一个完整的请求。**
>
> **　　413：请求提交的实体数据过大。**
>
> **　　414：uri请求过长，这种情况可将get请求改为post请求。**
>
> **　　415：请求提交的实体格式不对，比如某个接口只支持XML，提交格式为JSON则会报错。**
>
> **　　423：资源被锁定。**
>
> **　　429：请求次数过多。**
>
> **　　431：请求头字段过大。**
>
> **　　451：非法资源。**
>
> * **500：服务器遇到了不知如何处理的情况。主要错误是服务器内部错误，主要为用户权限的问题导致，或者是数据库连接出现了错误。**
>
> **　　501：服务器还是不具有请求功能的，而且是没有实施的，可以用来HttpWebRequest指定一个UserAgent来试试的，可以换电脑来测试一下，可以换不同类型浏览器测试。**
>
> **　　502：网关错误。可能原因：链接超时、服务器请求链接过多导致服务器无法正常响应。**
>
> **　　503：服务器正在维护或者暂停了，或者是cpu占用的频率大导致的。**
>
> * **504：请求超时，表示服务器一直在等请求响应回来但是等不到了。**
>
> **　　505：http的版本是不受支持的，需升级浏览器。**
>
> **　　507：服务器有内部配置错误**

## 分布式事务，分布式锁

#### 分布式事务

> 1：两段提交(2PC): 通过引入协调者来协调参与者的行为，并最终决定这些参与者是否要真正的执行事务。`协调者会问参与者是否执行成功`，参与者只有接收到了协调者发来的通知，才会进行提交，两个阶段：准备阶段和提交阶段。缺点：
>
> * 同步阻塞的：事务参与者再等待协调者的消息，无法进行其他操作
> * 单点问题：协调者作用非常大，发生故障将会造成，比如在第二阶段出现故障，
>
> 2： TCC,补偿(撤销)事务机制：针对每个操作，都要注册一个与其对应的确认和补偿（撤销）操作。它分为三个阶段：Try阶段，准备阶段，可以对数据进行冻结Confirm阶段， 主要是对业务系统做确认提交，Cancel阶段，如果第二阶段失败，调用解冻方法。
>
> * 缺点：在2,3步中都有可能失败。TCC属于应用层的一种补偿方式，所以需要程序员在实现的时候多写很多补偿的代码，在一些场景中，一些业务流程可能用TCC不太好定义及处理。
>
> 3： tx-lc，是有一个txmanager的协调者来管理数据，加入事务组，或者通知成功或者回滚，是本地事务协调，本身并不会产生事务
>
> 4:    seata 是两阶段提交事务，第一阶段解析业务sql并生成对应快照，第二阶段是提交/回滚，并删除快照

#### 分布式锁

> ‍

## SpringCloud

**印出来幂等性，分布式事务**

#### 3.Eureka和Zookeeper区别

> CAP定理：C：数据一致性。A：服务可用性。P：分区容错性（服务对网络分区故障的容错性）
>
> Eureka和Zookeeper就是CAP定理中的实现，Eureka（保证AP），Zookeeper（保证CP）

#### dubbo是如何使用的

> **把依赖导进来，主要要配置下dubbo的端口20880，以及zookeeper的地址**
>
> **要提供服务的地方添上@Service的注解，调用方想调用的话注入即可，**

#### dubbo和springcloud的区别

> 1. **dubbo由于是二进制的传输，占用带宽会更少**
> 2. **springCloud是http协议传输，带宽会比较多，同时使用http协议一般会使用JSON报文，消耗会更大**
> 3. **springcloud的接口协议约定比较自由且松散，需要有强有力的行政措施来限制接口无序升级**
> 4. **dubbo的注册中心可以选择zk,redis等多种，springcloud的注册中心能用eureka,nacos**

#### springcloud的介绍如果说到五大组件就具体介绍一下

> **eureka，服务注册与发现，阿里的nacos**
>
> **feign，服务间调用**
>
> **hystrix，服务熔断降级**
>
> **ribbon,负载均衡**
>
> **gateway，做网关**

## 一 JAVASE

#### 1 说一下异常的体系结构？

> **异常的根类是Threable，然后有两个直接子类，Exception和Error,然后直接继承Exception的是编译时异常，如果继承的是Exception的子类** `RuntimeException`，的异常是运行时异常。

#### 2 说一下常见的异常和错误？

> **常见的运行时异常有：**`NullPointerException`,`ClassNotFoundException`，`数组下标越界`，`类型转换异常`
>
> **常见的编译时异常有：**`文件找不到异常`，`sql异常`
>
> **常见错误：**`OOM`,`StackOverflowError`

#### 3 static关键字都能修饰什么？

> static关键字可以修饰的有类，成员变量，方法，代码块，导包
>
> 修饰类：内部类可以被修饰，修饰后是静态内部类
>
> 代码块：修饰代码块是静态代码块，这样会只在类加载的时候执行一次，用来做初始化操作
>
> 修饰方法：表示静态方法，在其中无法调用非静态方法或者非静态成员
>
> 修饰成员：表示这个属性属于类而不属于对象
>
> 修饰导包：这样导入的类中的静态成员可以直接声明，而不是类名点的形式

#### 4 说一下类加载的流程？

> 类加载的过程分为三个，加载，链接，初始化，而链接又分为验证，准备，解析。
>
> * 加载：就是加载字节码文件到jvm中
> * 链接：
>
>   * 验证：校验字节码文件是否有错误
>   * 准备：堆成员的变量进行初始化赋值，比如int默认0，对应一些无法确定的值，采用符号引用的方式进行占位。
>   * 解析：对上面的符号引用解析为具体的值。
> * 初始化：初始化成员信息，静态代码块会在这一阶段执行

#### 5 说一下Class.forName和loadClass区别？

> Class.forName会执行完整的类加载流程，而ClassLoader的loadClass方法不会执行链接操作

#### 6 说一下双亲委派机制？

> 双亲委派，更应该说是父类委派，也就是类加载的时候，在选择类加载器的时候总是先委派 `父类加载器`来加载，如果不能加载交给子类来加载。主要是防止破坏jdk核心的类，防止重复加载，比如最顶级的类加载器 `BootstrapClassloader`，就只负责加载jdk核心的类，然后 `ExcetionClassloader`负责加载拓展类，`AppClassloader` 负责加载项目ClassPath下面的类，然后是用户自己实现的ClassLoader

#### 7 JDK8中的新特性？

> lambda表达式
>
> stream
>
> 接口可以定义默认方法，静态方法，而不仅仅有抽象方法
>
> 新的日期类localtime,datetime,localdatetime
>
> Base64成为java的标准库

#### 8 说一说string,stirngbuffer,stringbuilder?

> String，是不可变字符串，为什么不可变，是类编写人员控制的，因为即便内部的char[]数组被final修饰，但是引用不变，值还是可以修改的，String每次做拼接操作都会创建一个新的对象，
>
> StringBuilder，是可变的，其实内部也是char[],是定义在父类AbstractStringBuilde的，然后每次append，通过System.arrayCopy来对char[]操作，实现的可变，然后不是线程安全的
>
> StringBuffer，是线程安全版本的StringBuilder，在各种方法上都加了同步关键字

#### 12 四种引用?

> `强引用`：Java中默认声明的就是强引用，只要强引用存在，垃圾回收器将永远不会回收被引用的对象，哪怕内存不足。
>
> `软引用`：在内存足够的时候，软引用对象不会被回收，只有在内存不足时，系统则会回收软引用对象 `SoftReference`。
>
> `弱引用`：无论内存是否足够，只要 JVM 开始进行垃圾回收，那些被弱引用关联的对象都会被回收，`WeakReference`。
>
> `虚引用`：虚引用是最弱的一种引用关系，如果一个对象仅持有虚引用，那么它就和没有任何引用一样，它随时可能会被回收.`PhantomReference`。

## 集合

#### 数组链表遍历差别

> 寻址次数链表要多一些。数组只需对基地址+元素大小*k就能找到第k个元素的地址 对其取地址就能获得该元素。链表要获得第k个元素，首先要在其第k-1个元素寻找到其next指针偏移，再将next指针作为地址获得值。多了一步寻址操作，当数据量大且其它操作较少时 这就有差距了

#### Set集合

> * HashSet：是Set接口（Set接口是继承了Collection接口的）最常用的实现类，顾名思义，底层是用了哈希表（散列/hash）算法。其底层其实也是一个数组，存在的意义是提供查询速度，插入的速度也是比较快，但是适用于少量数据的插入操作，判断两个对象是否相等的规则：1、equals比较为true；2、hashCode值相同。要求：要求存在在哈希表中的对象元素都得覆盖equals和hashCode方法。
> * LinkedHashSet：继承了HashSet类，所以它的底层用的也是哈希表的数据结构，但因为保持数据的先后添加顺序，所以又加了链表结构，但因为多加了一种数据结构，所以效率较低，不建议使用，如果要求一个集合急要保证元素不重复，也需要记录元素的先后添加顺序，才选择使用LinkedHashSet
> * TreeSet：Set接口的实现类，也拥有set接口的一般特性，但是不同的是他也实现了SortSet接口，它底层采用的是红黑树算法（红黑树就是满足一下红黑性质的二叉搜索树：①每个节点是黑色或者红色②根节点是黑色的③每个叶子结点是黑色的④如果一个节点是红色的，那么他的两个子节点是黑色的⑤对每个节点，从该节点到其所有的后代叶子结点的简单路径上，仅包含相同数目的黑色结点，红黑树是许多“平衡”搜索树的一种，可以保证在最坏情况下的基本操作集合的时间复杂度为O(lgn)。普及：二叉搜索树的性质：它或者是一棵空树；或者是具有下列性质的二叉树：若左子树不空，则左子树上所有结点的值均小于它的根结点的值；若右子树不空，则右子树上所有结点的值均大于它的根结点的值；左、右子树也分别为二叉排序树。若子树为空，查找不成功。），要注意的是在TreeSet集合中只能存储相同类型对象的引用。

#### Map集合

> * `HashMap`：哈希表的实现原理中，先采用一个数组表示位桶，每个位桶的实现在1.8之前都是使用链表，但当每个位桶的数据较多的时候，链表查询的效率就会不高，因此在1.8之后，当位桶的数据超过阈值（8）的时候，就会采用红黑树来存储该位桶的数据（在阈值之前还是使用链表来进行存储），所以，哈希表的实现包括数组+链表+红黑树，在使用哈希表的集合中我们都认为他们的增删改查操作的时间复杂度都是O(1)的，不过常数项很大，因为哈希函数在进行计算的代价比较高,HashMap和Hashtable类似，不同之处在于HashMap是非同步的，并且允许null，即null value和null key。，但是将HashMap视为Collection时（values()方法可返回Collection），其迭代子操作时间开销和HashMap 的容量成比例。因此，如果迭代操作的性能相当重要的话，不要将HashMap的初始化容量设得过高，或者load factor过低。
> * `TreeMap`：TreeMap 是一个有序的key-value集合，它是通过红黑树实现的。TreeMap 继承于AbstractMap，所以它是一个Map，即一个key-value集合。TreeMap 实现了NavigableMap接口，意味着它支持一系列的导航方法。比如返回有序的key集合。TreeMap 实现了Cloneable接口，意味着它能被克隆。TreeMap 实现了java.io.Serializable接口，意味着它支持序列化。
>
> TreeMap基于红黑树（Red-Black tree）实现。该映射根据其键的自然顺序进行排序，或者根据创建映射时提供的 Comparator 进行排序，具体取决于使用的构造方法。TreeMap的基本操作 containsKey、get、put 和 remove 的时间复杂度是 log(n) 。另外，TreeMap是非同步的。 它的iterator 方法返回的迭代器是fail-fastl的。
>
> * `HashTable`: Hashtable继承Map接口，实现一个key-value映射的哈希表。任何非空（non-null）的对象都可作为key或者value，线程安全。

#### list集合

> 普通的List
>
> 1.ArrayList集合：
>
> * 底层数据结构是数组，查找快，增删慢。
> * 线程不安全，效率高
>
> 2.Vector集合：
>
> * 底层数据结构是数组，查询快，增删慢
> * 线程安全，效率低
>
> 3.LinkedList集合:
>
> * 底层数据结构是链表，查询慢，增删快
> * 线程不安全，效率高
>
> 线程安全的集合
>
> 1. CopyOnWriteArrayList
>
>    * JUC包下线程安全的List,里面使用了可重入锁，Arrays.copyOf
>    * 读多写少的情况下，推荐使用CopyOnWriteArrayList方式
> 2. 读少写多的情况下，推荐使用 `Collections.synchronizedList()`的方式

#### hashmap是如何实现添加数据的，具体如何计算的hash值，满了如何填。

> put方法会调一个putVal的方法，在这之前会先调一个hash的方法，
>
> 计算hash值：就是hashcode值与hash值无符号右移16位然后异或后得到hash值

#### 说一说hashMap的扩容原理？

> 首先HashMap在jdk8中已经由原来的桶+链表变为桶+链表+红黑树的形式，然后当达到扩容的阈值，比如默认的负载因子0.75,初始容量为16的时候，当put完成后，判断长度为12的时候，就会执行 `resize()`方法进行数组扩容为原来的2倍。如果链表长度大于等于8，并且数据长度小于64时，也会扩容。
>
> 扩容时，会将指定的位置的key的hash值与原数组的长度进行&amp;运算，如果结果为0放在原位置，如果结果 不为0放到新数组的 `原位置+数组长度`的地方

#### ConcurrentHashMap如何保证的线程安全？HashMap为何不去安全？

> HashMap不安全的地方：
>
> * 在7的时候，扩容可能存在环形链表，到了1.8就解决了这个问题，因为1.7的时头插法
> * 方法不同步，插入数据在多线程情况会出现数据覆盖的情况
> * 内存存在modCount++,这种不原子的操作
>
> 而ConcurrentHashMap在1.7和1.8是不同的实现：
>
> 1.7：是由一个Segment数组和多个HashEntry数组组成，其实就是将HashMap分为多个小HashMap,每个Segment元素维护一个小HashMap,目的是锁分离，本来实现同步，直接可以是对整个HashMap加锁，但是加锁粒度太大，影响并发性能，所以变换成此结构，仅仅对Segment元素加锁，降低锁粒度，提高并发性能。
>
> 1.8：是数组+链表，或者数组+红黑树结构,并发控制使用Synchronized关键字和CAS操作。下面会从源码角度讲解jdk1.8 ConcurrentHashMap控制线程同步的原理

#### 说一说hashMap的扩容原理？

> 首先HashMap在jdk8中已经由原来的桶+链表变为桶+链表+红黑树的形式，然后当达到扩容的阈值，比如默认的负载因子0.75,初始容量为16的时候，当put完成后，判断长度为12的时候，就会执行 `resize()`方法进行数组扩容为原来的2倍。如果链表长度大于等于8，并且数据长度小于64时，也会扩容。
>
> 扩容时，会将指定的位置的key的hash值与原数组的长度进行&amp;运算，如果结果为0放在原位置，如果结果 不为0放到新数组的 `原位置+数组长度`的地方

#### 什么是CAS

> CAS也就是 `Compare and Swap` 比较并交换，是基于sum.misc包下的 `UnSalf`中的native方法实现的。
>
> 存在的问题：
>
> * 占用资源：每次失败都会自旋，然后继续占用cpu资源，如果解决？可以使用LongAddr，每次CAS失败不会直接去自旋而是存储到数组里，或者使用同步代码块，synchronized有自适应自旋锁，自旋到一定程度，就会挂起
> * ABA问题：加版本号，加时间戳.....

#### arraylist是如何添加数据，满了怎么填，具体到原理

> add方法添加后会先判断是否需要扩容，然后添加到数组的size的长度的位置。
>
> 扩容的话是在一个grow的方法中，计算新的长度就是：老的长度+老的长度右移一位，简单来说就是 每次多1/2，然后调用Arrays.copyOf进行扩容

## 二 多线程

#### 线程停止方式

> interrupt()：中断线程
>
> stop()：强行终止线程，不推荐使用

#### 线程池3种终止方式比较

| **方法**             | **执行中的任务**      | **等待队列的任务**       | **将来提交的任务** | **返回值**         |
| -------------------------- | --------------------------- | ------------------------------ | ------------------------ | ------------------------ |
| **shutdown**         | **正常执行**          | **正常执行**             | **拒绝**           | **无**             |
| **shutdownNow**      | **尝试interrupt中断** | **忽略不执行，返回列表** | **拒绝**           | **未执行任务列表** |
| **awaitTermination** | **正常执行**          | **正常执行**             | **正常接收**       | **是否超时**       |

#### 线程池的使用场景

> * 耗时任务HTTP超时
> * 多任务，分别都有需要些时间，5s,5s,6s,就可以开三个线程，然后使用CountDownLatch阻塞，然后返回
> * 数据拆分，比如一万个数据，拆分为1000*10，每个task 分布式执行

#### CountDownLatch和CyclicBarrier?

> countdownLatch：设置一个线程个数，然后主线程在等待，每次子线程完成任务调用countDown()方法的时候这个值-1，然后到0的时候继续执行了。
>
> cyclicBarrier：设置一个阈值，有个计数器初始为0，每次调用await方法后+1，这个值达到指定的阈值，则释放所有的等待线程，
>
> CyclicBarrier可重复使用，计数器达到阈值则清零，可以再使用

#### 什么是线程以及进程？

> 进程是一个程序的执行过程，是与程序相关的。线程是一个比进程更小的执行单位，一个进程可以有多个线程，

#### 1 线程创建方式？

> 继承Thrand类，
>
> 实现Runnable接口，
>
> 实现callable接口
>
> 线程池

#### 2 线程的状态？

> 新建状态：线程刚刚创建
>
> 就绪状态：调用start方法后，除了cpu之外其他的资源全部就绪
>
> 运行状态：获取到了cpu，开始执行自己的代码
>
> 阻塞状态：因为某种原因放弃了cpu的使用权，暂时停止运行
>
> 销毁状态：线程执行完成了或者异常退出

#### 4 synchronized在jdk1.6的优化？

> java中在对象的头中存放了锁的信息，在对象头中存放有：指向类对象的指针，对象长度，以及 `markword`，这里就存放着锁的信息，gc标记等。
>
> 这里要说下锁膨胀：
>
> * 锁膨胀：也就是锁的升级，往重量的方向升级。
> * 锁撤销：升起前的操作，由于要换锁了，当前锁失效了就要撤销。
>
> 锁一共有如下的特点：
>
> 1. `锁消除`：在编译器有一种优化叫 `逃逸分析`，分析对象的作用域，如果证明一个对象不会逃逸到对象的方法外，如果说对象不会被方法外访问到，会删除掉同步关键字
> 2. `锁粗化`：如果有对同一个对象连续的加锁解锁操作，那么就会将锁范围扩大到外面，粗话锁的范围，减少加锁，开锁的开销。
> 3. `偏向锁`：偏是偏心的意思，这个锁会偏向于第一个获得它的线程，如果没有其他线程来竞争，则不会进行加锁，开锁的操作，如果有其他线程，也就是存在竞争则升级为轻量级锁。
> 4. `轻量级锁`：轻量级锁一共有如下两种：
>
> * `自旋锁`：为了避免线程在争夺共享资源时候频繁的挂起和创建，会让一个线程自旋，默认自旋次数是10
> * `自适应自旋锁`：自旋的次数不再固定了，如果在一个锁对象上一个线程刚刚获得过锁，但线程有另一个线程持有锁并正在运行，会认为这个线程很有可能在接下来获得锁对象，因此虚拟机会让其资源更多的次数，相对的如果少，则自旋次数也少。
>
> 5. `重量级锁`：一个线程很少的获取该锁，如果成功获取到这个锁，则会膨胀为重量级锁，重量级锁有
>
> * `互斥锁`：如果一个线程拿到锁后，会将其他要获取这个锁的线程挂起。挂起，唤醒，会很消耗性能。

#### 5 什么是AQS？

> AQS是一个在JUC包下名叫 `AbstractQueuedSynchronizer`的抽象类，AQS里面有一个双向队列，里面存放没有获取到资源排队的线程对象，有一个被volatile修饰的成员变量 `state`表示加锁的状态，JUC很多队列，锁都是基于这个实现的

#### 6 ThreadLocal?

> ThreadLocal可以创建线程的本地变量，每个线程都可以拥有自己的变量，但是ThreadLocal会有内存泄漏问题。因为在ThreadLocal内部有一个内部类 `ThreadLocalMap`来存放值，其中Map的每个节点Entry都是继承 `WeaKReference`，也就是弱引用，当前线程对象作为值存放在弱引用中，而值并不是，因此当一个线程被销毁时候，可达性分析不满足的时候，这个线程对象就可能被回收，而值并没有被回收，这样就出现了内存泄露问题

#### 7 说一说自带的线程池?

> * `newSingleThreadExecutor` ：创建一个单线程的线程池，如果这个线程异常结束，会创建另一个线程来代替。newSingleThreadExecutor能确保依照任务在队列中的顺序来串行执行。
> * `newFixedThreadPool`：创建一个固定大小的线程池，每次提交一个任务就会创建一个线程，直到最大值
> * `newCachedThreadPool`：创建一个可缓存的线程池。如果线程池的大小超过了处理任务所需要的线程，如果线程池的当前规模超过了处理需求时，那么就会回收部分空闲的线程（根据空闲时间来回收），当需求增加时，此线程池又可以智能的添加新线程来处理任务。此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说JVM）能够创建的最大线程大小。
> * `newScheduledThreadPool`：创建一个定长线程池，以延迟或定时或周期的方式来执行任务，类似于Timer。可应用于重发机制。
> * `newWorkStealingPool()`:这个是 JDK1.8 版本加入的一种线程池,stealing 翻译为抢断、窃取的意思
> * `newSingleThreadScheduledExecutor()`:单线程的定时线程池

#### 8 线程池的七个参数？

> 核心线程数，最大线程数，等待时间，时间单位，等待队列，创建线程的工厂，拒绝策略
>
> 其中拒绝策略有：
>
> * `AbortPolicy`：丢弃任务，抛出异常
> * `DiscardPolicy`：丢弃任务，不抛出异常
> * `DiscardOldestPolicy`：喜新厌旧，丢弃最早的任务
> * `CallerRunsPolicy`：由调用者来执行
>
> 线程池执行顺序：
>
> 首先看核心，不够放队列，队列满了，看最大，最大满了看拒绝策略

#### 9 阻塞队列？

| **队列**                  | **有界性**   | **锁**   | **数据结构**   |
| ------------------------------- | ------------------ | -------------- | -------------------- |
| **ArrayBlockingQueue**    | **有界**     | **加锁** | **arrayList**  |
| **LinkedBlockingQueue**   | **可选有界** | **加锁** | **linkedList** |
| **PriorityBlockingQueue** | **无界**     | **加锁** | **heap**       |
| **DelayQueue**            | **无界**     | **加锁** | **heap**       |
| **SynchronousQueue**      | **有界**     | **加锁** | **无**         |

> * ArrayBlockingQueue：基于数组的有限阻塞队列，插入数据和取出数据公用一个锁对象。先进先出原则
> * LinkedBlockingQueue：基于链表的阻塞队列。先进先出原则。newFixedThreadPool 和 newSingleThreadExecutor 使用这个队列
> * PriorityBlockingQueue： 有优先级的无限阻塞队列，基于最小二叉堆实现
> * DelayQueue： 每个元素指定延时时间，只有当时间到了才能从队列中获取该元素，是一个无限队列。
> * SynchronousQueue：存储元素的阻塞队列，插入操作必须等待一个线程调用移除操作，否则一直会阻塞。newCachedTHreadPool 使用这个队列

## 三 JVM

#### 可视化界面

> Jconsole, jmc,jvisalVM

#### GC流程

> 首先介绍一下JVM中堆内存的组成：JVM堆内存主要由三部分组成:
> (1)新生代:伊甸园区,存活区,伸缩区
> (2)老年代:老年区,伸缩区
> (3)元空间(永久代):元空间,伸缩区       注意:JDK1.8以后,永久代被称作元空间：直接使用物理内存
>
> GC流程:
> ** （1）新生对象在新生代的伊甸园区开辟空间，如果伊甸园区的内存空间不足,则发生MinorGC,进行垃圾回收处理,然后再判断处理之后的内存空间是否充足,       如果充足,则将新生对象存放在伊甸园区,否则将继续判断存活区的内存空间**
> （2）如果存活区的内存空间充足,则将伊甸园区的部分活跃对象直接存放在存活区内,如果存活区也没有多余的内存空间,那么将继续判断老年区的内存空间
> ** （3）如果老年区的内存空间充足,则将伊甸园区的部分活跃对象存在老年区中,如果老年区也没有多余的内存空间,那么将会发生MajorGC(FullGC),       然后判断老年区是否有多余的内存空间,如果有多余的空间,则可以将对象保存在老年区。否则将会产生OOM(OutOfMemoryError)异常**
> **  年轻代：采用复制算法(将活跃对象复制到完全未使用的内存空间中,然后对需要垃圾回收的对象进行GC处理)   老年代:采用整理-压缩算法(将需要回收的对象进行整理-压缩)    注意:GC处理只针对新生代和老年代,元空间(永久代)不在GC控制范围内     **

#### 1 JVM内存模型?

> **线程私有的有：程序计数器，虚拟机栈，本地方法栈**
>
> * 程序计数器，可以记录方法执行到了哪里，比如执行到第十行，跳到了另一个方法中，程序计数器就 可以保证这个方法执行完毕还能回到第十行
> * 虚拟机栈：执行java方法的栈
> * 本地方法栈：执行native方法
>
> **线程共享的有：堆，方法区**
>
> * 堆：对象信息存放位置
> * 方法区：针对不同版本位置和内容都不同：
>
>   * 1.6 时候叫永久代：类信息，静态信息，符号引用，运行时常量池都存在这里
>   * 1.7 还是叫永久代，但是把运行时常量池放到了堆中
>   * 1.8 叫原空间，原空间直接独立于jvm，直接存在内存中

#### 2 Java中标记垃圾的算法？

> * **引用计数法（现在不用了……）：给每一个对象添加一个计数器，被引用，计数器+1，移除引用计数器-1，当一个对象的计数器为0时，标记为垃圾对象。 **
> * 根搜索算法、可达性分析（大多数垃圾回收器默认使用）：以GCRoot为根，向下引用，所有可以被引用到对象，就是可用对象。没有引用到的对象就是垃圾。
>   GCRoot：虚拟机栈中的引用，本地方法栈中的引用，静态引用，运行时常量池，类信息Class `<T>`

#### 3 说一下什么是SWT？

> SWT就是 `Stop The World` ,在执行GC的时候，全部的线程挂起，除了垃圾回收线程。

#### 4 说一下三色标记？

> 黑色：标记过当前对象，并且当前对象内部的引用也被标记过
>
> 灰色：标记过当前对象，但是对象内部的引用没有被标记
>
> 白色：没有被标记的对象，当执行GC的时候将会被收集

#### 5 Java中回收、收集垃圾的算法？

> * **复制清除：	**优点：速度快，没有内存碎片问题。		缺点：空间利用率不高。
> * 标记清除：	优点：速度快，空间利用率高		缺点：有内存碎片问题。
> * **标记整理/压缩：	**优点：空间利用率高，没有内存碎片问题。		缺点：速度较慢。
> * 分代收集（基本所有常见的垃圾回收器使用的算法）：
>   **	将堆内存分为了新生代和老年代，比例默认为1:2
>   **		新生代采用优化后的复制清除：Eden，from，to，比例默认为8:1:1
>   **			将Eden和from中可用的对象复制到to中，回收整个Eden和from，to变成from，from变成to
>   **			只要Eden满了，执行新生代GC
>   **		老年代采用传统的标记清除，标记压缩：
>   **			传统方式………………
>
> JVM优化的目的：让GC时间变短，避免FULL GC，避免OOM……

#### 6 说一下常见的垃圾收集器？

| **Serial**       | **单线程** | **串行** | **新生代**                   |
| ---------------------- | ---------------- | -------------- | ---------------------------------- |
| **Serial Old**   | **单线程** | **串行** | **老年代**                   |
| **Parallel**     | **多线程** | **串行** | **新生代（jdk8默认新生代）** |
| **Parallel Old** | **多线程** | **串行** | **老年代（jdk8默认老年代）** |
| **ParNew**       | **多线程** | **串行** | **新生代**                   |
| **CMS**          | **多线程** | **并行** | **老年代（标记清除）**       |
| **G1**           | **多线程** | **串行** | **新生代和老年代**           |

#### 7 说一下CMS的执行流程？

> 1. 初始标记：找出 `GCROOT`,这个时候会触发SWT
> 2. 并发标记：并发的执行三色标记，因为是并发可能出现，错标，漏标的情况
> 3. 重新标记：非并发的标记，来解决并发标记的问题，也会触发SWT
> 4. 并发清除：开始执行GC

## 四 MySQL

#### SQL优化

> 查询优化：
>
> * 查询优化：比如多条件查询 可以通过UNION连接
> * 添加优化：批量添加添加数据有values()，()可添加多个
> * 删除优化：包括批量删除，条件，也可以吧比如说in语句优化为UNION
>
> 语句优化：
>
> * in 优化为 union，如果是连续的值可以使用 between and
> * 查询的like 不要使用左%
> * 包括像：分页的limit优化
> * 尽量避免在范围查询比如或&lt;&gt;操作符
>
> 其他：
>
> * 使用逻辑外键，不要使用物理外键
> * 不要做列运算比如说 where age+1=10
> * 查询的对索引列要满足最左原则
>
> 慢SQL查询：
>
> 找到sql后使用explain查看执行计划，然后其中可以看到比如：
>
> * key字段：使用的索引是什么
> * type：访问类型：ALL、index、range、 ref、eq_ref、const、system、`NULL（从左到右，性能从差到好)`

#### 1 事务的四大特性？

> 原子性：事务内的sql总是都成功或者都失败。
>
> 持续性：事务完成后将永久的写入到数据库
>
> 一致性：事务前后数据的总量是一致的
>
> 隔离性：事务之间是互相隔离的

#### 2 事务的传播特性？

> 在多个事务嵌套的情况下，事务的执行会有如下的特点：
>
> * `required`:将内部事务挂起，使用外部事务(mysql默认)
> * `required_new`:不管有没有事务都要创建新的事务
> * `supports`:有事务就使用，没有事务就不使用
> * `not_supports`:不使用事务，有也不用
> * `never`:不使用事务，有报错

#### 3 事务的隔离级别

> * 读未提交：无法解决问题
> * 读已提交：解决脏读问题
> * 可重复读：解决脏读，不可重复读问题
> * 串行化：加锁

#### 4 不考虑事务隔离级别会存在哪些问题？

> * 脏读：一个事务读取到另一个事务还没提交的事务
> * 幻读：一个事务中，前面读取到了数据，后面读取不到了，好像出现了幻觉
> * 不可重复读：在同一个事务中前后两次读取的数据不一样，有其他事务修改了值

#### 5 mysql常见的存储引擎？

> * Innodb: 支持事务，支持外键，支持主键自增长，然后支持行级锁，(mysql默认)
> * MyIASM: 不支持事务，不支持外键，支持表锁

#### 6 mysql常见索引，啥时候用？

> 索引有如下：聚簇索引和非聚簇索引：
>
> 主键索引：也叫聚簇索引，根据主键搜索就会用到这个索引，查询速度很快
>
> 唯一索引：当列加唯一约束的时候会有次索引
>
> 普通索引：对于普通列的索引
>
> 组合索引：符合最左原则，比如（a,b,c）索引，查询条件有a和b就会用到索引，然后查询条件为a和c就只有a用到c用不到
>
> 全表索引：全部列都有的索引
>
> 使用场景，一般常用主键以及唯一索引，而其余索引，是在sql优化的时候再看，比如一条sql很慢，到时候看下执行计划，这个时候才考虑加不加索引

#### 创建索引的语句？

> create index 索引名 表名 （索引哪些列）

#### sql中使用了索引，回表是怎么回事，如何避免?

> 回表就是比如查询一个订单的时间和订单名称，条件是订单名称，订单名称是有索引但不是聚簇索引，而时间没索引，像这样查询到的字段中有索引不包含的内容的时候就会回表，这样就会查询多次，第一次根据非聚簇索引找到主键id，然后第二次根据主键id查询到结果值
>
> 使用覆盖索引即可避免回表，覆盖索引就是加索引，索引的内容完全覆盖所有要查询的列，这样数据数据列只用从索引中就能够取得。

#### 数据库有abc三个字段，组合索引，where b=1,c=2会使用这个索引吗？

> 会使用，因为满足最左原则，而如果这里的条件是c&gt;2子类的范围条件就会打破这个原则

#### 物理外键逻辑外键？

> 物理外键就是真实存在的外键，是通过外键约束添加的，而逻辑外键是不存在的，是只逻辑上有的外键，因为物理外键每次会检测是否满足外键约束，因此会影响性能，通常都会使用逻辑外键

## 五 MyBatis

1 说一下mybatis的一，二级缓存？

> 一级缓存：默认开启，范围是sqlSession，使用同一个sqlSession前两次执行查询，后一次将调用缓存中的值也就是一个HashMap叫 `Local Cache`，
>
> 二级缓存：默认是关闭的，与开启有关的有：
>
> * mybatis的配置文件中，在设置标签中 `cacheEnabled`默认是true
> * 需要在mapper文件中加入 `cache`标签来开启，
> * 在mapper的标签中加入 `useCache`属性，只有当前标签的语句会缓存
> * 以及 `flashCache`属性：当此条语句执行将刷新缓存
>
> 二级缓存有如下的特点：
>
> * 二级缓存的范围是sqlSessionFactory
> * 所有的查询都将被缓存
> * 当前mapper执行dml的时候将会刷新缓存，
> * 然后缓存默认使用的 `LRU`：最近最少使用算法来进行回收缓存
> * 缓存大小默认是1024，可以在cache标签中进行配置大小

#### 2 mybatis的执行器有哪些？

> CachingExcetor：查询二级缓存
>
> BaseExcetor：如果开启了一级缓存就会找这个
>
> SimpleExcetor：执行sql进行查询
>
> ReuseExcetor：里面有statment的map，封装的jdbc操作
>
> BatchExcetor：批处理的执行器

#### 3 MyBatis和数据库交互的原理？

> 基于JDK动态代理生成的Mapper对象执行方法，方法中会调用SqlSession的selectList方法，selectList会调用CachingExecutor查询二级缓存，CachingExecutor会调用BaseExecutor查询一级缓存，会根据核心配置文件的策略选择SimpleExecutor/ReuseExecutor/BatchExecutor与数据库交互，交互的过程会涉及到大量的Handler（PreparedStatementHandler，ResultSetHandler，TypeHandler……）

#### mybatis如何实现一对多，或者多对多？

> ‍

## 六 Spring

#### spring启动加载

> 作为CommandLineRunner的实现类，会加入springboot的args参数
> springboot启动执行这个run方法

#### 介绍一下spring

> 这三个Map也叫缓存都是定义在： **`DefaultSingletonBeanRegistry` (默认的单例Bean注册表)，其中三级缓存都在下面，early的意思是早期的，因此earlySingletonObjetcs是存放为实例化完全，提前暴漏的bean，这就是二级缓存

#### 4 在哪里用到了AOP

> 异常处理，
>
> 框架中：
>
> * 事务
> * 权限控制

#### 1 spring三级缓存？如何解决的的循环依赖？

> spring的三级缓存分别为：
>
> * 三级缓存：singletonFactories：存放Bean工厂
> * 二级缓存：earlySingletonObjects：存放提前暴漏的bean
> * 一级缓存：singletonObjetcs：存放初始化完成的bean，ioc的bean都在这里面，是一个长度为256的 `ConcurrentHashMap`
>
> 循环依赖问题：
>
> 两个对象AB互相依赖，首先要创建A，先将A的

#### 2 springBean创建流程？

> ‍

#### 3 springmvc执行流程？

> **前端请求发到到** `DispatcherServlet`，然后会到 `HandlerMapping`中拿到装载好的全部的handler，之后到 `HandlerAdaptor`，再这里对请求或者相应的参数做转化，对不同的类型数据，通过不同的转换器进行处理，知道就到了我们写的controller，当返回的时候到 `HandlerAdaptor`，如果返回的是视图，就会转到 `VirwResolver`找到页面文件然后返回。

#### 4 springbean生命周期？

#### 5 springboot自动装配？

> **简单来说就是写好了配置类，然后会自动的扫描到然后将bean注入。**
>
> **在启动类上的注解** `@SpringbootApplication`里面有 `@EnableAutoConfiguration`，其中导入了一个类：`AutoConfigurationImportSelector`，最后是找到很多的配置类，有各种@Bean注解

#### 6 springBean的作用域？

| **作用域**      | **描述**                                                                                                               |
| --------------------- | ---------------------------------------------------------------------------------------------------------------------------- |
| **singleton**   | **在spring IoC容器仅存在一个Bean实例，Bean以单例方式存在，bean作用域范围的默认值。**                                   |
| **prototype**   | **每次从容器中调用Bean时，都返回一个新的实例，即每次调用getBean()时，相当于执行newXxxBean()。**                        |
| **request**     | **每次HTTP请求都会创建一个新的Bean，该作用域仅适用于web的Spring WebApplicationContext环境。**                          |
| **session**     | **同一个HTTP Session共享一个Bean，不同Session使用不同的Bean。该作用域仅适用于web的Spring WebApplicationContext环境。** |
| **application** | **限定一个Bean的作用域为** `ServletContext`的生命周期。该作用域仅适用于web的Spring WebApplicationContext环境。       |

#### 7 异常处理

> 1. **针对每个Controller都写一个自己的异常处理方法：通过注解ExceptionHandler标识这个conroller出现异常则执行这个方法，从而更为友好的返回**
>
> ```
>  @Controller
>  public class TestController {
>      @ResponseBody
>      public Object demo1(){
>          int i = 1 / 0;
>          return new Date();
>      }
>      @ExceptionHandler({RuntimeException.class})
>      public ModelAndView fix(Exception ex){
>          System.out.println("do This");
>          return new ModelAndView("error",new ModelMap("ex",ex.getMessage()));
>      }
>  }
> ```
>
> 2. **全局的异常处理，在类上加上@ControllerAdvice注解，然后类中可以写多个方法，每个方法都可以有自己的@ExceptionHandler，针对不同的异常做不同的处理**

#### Spring 事务注解啥时候会失效？

> **自己代码加 try catch**
>
> **方法 不能是private**

## 七 Linux

#### 1 Linux如何查看进程pid，并且杀死进程？

> * **ps -ef ：查看全部进程**
> * **ps -ef | grep 要搜索的进程 ：查询指定的进程**
> * **kill -9 进程pid：杀死进程**
>
> **如果是java进程可以通过** `jps`就可以查到

#### 2 Linux查看日志的命令？

> **tail 日志 # 从文件末尾看**
>
> **tail -f 日志 # 实时 监控文件的变化**
>
> **如果是docker容器可以使用docker logs -f 容器标识 来查看**

#### 3 linux的常用命令

> **1 查看进程pid**
>
> **ps -ef ：查看全部进程**
>
> **ps -ef | grep 要搜索的进程 ：查询指定的进程**
>
> **kill -9 进程pid：杀死进程**
>
> **如果是java进程可以通过** `jps`就可以查到
>
> **2 Linux查看日志的命令？**
>
> **tail 日志 # 从文件末尾看**
>
> **tail -f 日志 # 实时 监控文件的变化**
>
> **如果是docker容器可以使用docker logs -f 容器标识 来查看**
>
> **3 修改目录，文件的mv，cp**
>
> **4 文件操作**
>
> **创建touch，编辑vim，文件查看cat，**
>
> **5 权限操作**
>
> **chmod rwx:读写运行**

## 八 ES

**什么是es?**

> **es是开源的一种分布式搜索引擎，通过倒排索引的方式进行全文检索，海量的数据很快的速度就能返回结果**

#### 1 什么是倒排索引？

> **倒排索引就是，es会将每个可分词字段进行分词，然后存储在分词库中，其中每个词都会有对应的文档索引，这样每次查询根据分好的词可以直接找到对应的文档， 速度非常快。**

#### 2 es的date类型时区问题？

> **es会将传入的时间-8小时后展示，如果是时间戳，**

#### 3 es有几种搜索？

> 1. **term查询 ：es最基本的查询，高级的查询的底层也是根据这个整的，term查询对比MySQL的话，相当于：where column = ？，特点：term不会将用户输入的关键字进行分词，直接拿用户的完整关键字匹配分词库。**
> 2. **match查询：查询是使用频率最高的查询方式，match查询的底层还是term查询。查询会根据查询的field的属性，决定是否将用户输入的关键字进行分词**
>
> * **如果field是keyword类型，match查询不会将用户输入的关键字进行分词**
> * **如果field是text类型，match查询会将用户输入的关键字进行分词**
>
> 3. **range查询：range查询可以实现范围检索。针对数值，时间和IP地址做范围查询**
> 4. **复合查询(bool查询)，可以设置多条件，bool查询提供了四种组合方式：**
>
>    * **must：等于MySQL的and**
>    * **should：等于MySQL的or**
>    * **must_not：等于MySQL的!**
>    * **filter：在query的筛选基础上，再次做筛选，这次筛选不会计算分数**
> 5. **高亮查询：将用户输入的关键字匹配项，以高亮的形式返回。**

#### 4 es提升查询效率？

> * **根据数据量，可以将数据全部缓存的cache中。**
> * **将es中一些经常被查询的数据，存放到cache中。基于定时任务一定时间内查询一次热点数据，热点数据就存放到cache中。**
> * **根据业务情况，只让用户查询一定时间内的数据，让线上部署的ES中数据量没那么大，查询效率会变高。**
> * **增加备份节点数量。**
> * **分页问题，避免深分页。  ES提供了scroll分页。**

## 九 radis

#### 缓存30分钟内访问最多的数据

> ‍

#### Redis项目中哪里使用，具体场景，

> **像登陆的短信，**
>
> **做那种中心化的登陆，可以用redis，**
>
> **首页商品信息，也就是热点数据**

#### Redis集群

> **1 主从架构，主负责读写， 从负责读，从会连接主同步数据，**
>
> **2 哨兵机制，就是主节点宕机了，从节点会自动选举出一位新的主节点，当原来的主节点如果在恢复重新上线的时候，选举的新主节点会变为从节点，然后一位内涉及到选举投票，因此选举一定要是奇数个**
>
> **3 集群，多个redis然后数据会根据一种hash运算，对运算结果对16384取余，然后得到一个0-16383的数据，然后每个集群节点会只负责这一部分数据。**

#### redis持久化机制

> **如果Redis宕机，存储在内存的全部数据都会丢失。Redis提供了两种方案来持久化内存中的数据。分为：**
>
> **RDB和AOF（Append Only File）**
>
> ##### 8.2.1 RDB（Redis Data Base）
>
>> **RDB是Redis默认的持久化机制，也是默认开启**
>>
>> * **RDB基于二进制方式持久化数据。（持久化文件里的东西是二进制的）**
>> * **RDB持久化时机：在一定时间内写了多少个key，就执行一次RDB持久化。**
>> * **RDB优缺点：**
>>
>>   * **持久化和数据恢复速度很快……**
>>   * **无法保证数据安全，数据可能会丢失………**
>>
>
> ##### 8.2.2 AOF（Append Only File）
>
>> **AOF持久化机制默认是关闭的。**
>>
>> * **AOF基于日志的形式持久化数据。（将所有的写操作命令保存到文本文件）**
>> * **AOF持久化时机：**
>>
>>   * **always：只要只写了写操作，立即执行持久化……**
>>   * **everysec：每秒执行一次持久化操作……（默认）**
>>   * **no：根据操作系统和资源的情况，一定时间内执行一次，时间是不确定了……**
>> * **AOF优缺点：**
>>
>>   * **持久化和数据恢复速度相对RDB比较慢……**
>>   * **相比RDB更能保证数据的安全……**
>>
>
> `Ps：Redis官方推荐同时开启RDB和AOF持久化方案……`
>
> **注意实现：恢复数据时，AOF的优先级更高。 在RDB执行持久化时，基于AOF持久化文件进行持久化。**
>
> **AOF文件会随着写操作的增多，越来越大，可以选择将AOF文件进行重写：**
>
> * **自动重写：**
>
>   ```
>    auto-aof-rewrite-percentage 100     # 当AOF文件超过初始大小的一倍时，执行一次持久化
>    auto-aof-rewrite-min-size 64mb      # AOF文件重写要求文件至少要64M
>   ```
> * **手动重写：**
>
>   ```
>    BGREWRITEAOF
>   ```
>
> **AOF重写之后，文件内的所有命令会转换为跟RDB一样的二进制数据。**
>
> **基于执行写操作，会在二进制数据下基于保存写操作命令。**

#### 2 redis的set和Zset

> * **set就像是java的set一样：有序集合,并且不能重复**
> * **zset：有序，不能重复，然后有序：类似于Java的SortedSet和HashMap的结合体，一方面它是一个set，保证了内部value的唯一性，另一方面它可以给每个value赋予一个score，代表这个value的排序权重。它的内部实现用的是&quot;跳跃列表&quot;的数据结构。**

#### redis的存储结构有哪些？

> **key-string ：值是字符串**
>
> **key-map：值就是键值对的map**
>
> **key-list:   值是一个集合，有序集合，有下标**
>
> **key-set：存储无序，不允许重复，无下标**
>
> **key-zset：有序的set,有下标**

#### redis命令

> **decr：是-1操作**

#### redis持久化方式

> **RDB: 二进制，save second key**
> **AOF: 日志，always，everysec，no**
> **同时开启： AOF优先级高，RDB会基于AOF执行持久化**
> **AOF文件过大，AOF重写**

#### 1 Redis集群架构特点？

> **将请求命令的key进行crc16运算，将结果对16384取余，根据结果选择指定的集群节点操作……**

#### 3  说一下什么是缓存击穿？

> **问题：redis中的大量热点数据同时到期，导致大量的请求到达mysql，导致msql宕机**
>
> **解决方式：**
>
> * **热点数据生存时间不应该同时到期，没查询一次就增加一点生存时间，**
> * **查询数据库之前加锁，**

#### 4 说一下什么是缓存穿透？

> **问题：大量请求来查询，这个数据redis没有，mysql没有，导致mysql宕机**
>
> **解决方式：**
>
> * **针对大量请求的ip进行封禁**
> * **在redis中针对不存在的数据存储null值**
> * **先通过布隆过滤器查询数据是否存在，然后再查询数据库**
>
> **什么是布隆过滤器？：**
>
> **布隆过滤器是一个bitmap，在比特位上存储0表示数据不存在，1表示存在，然后不了过滤器并不很精准，如果没有一定没有，如果有可能没有，因为可能存在hash冲突**
>
> **如何提升布隆过滤器的精度？：**
>
> **加大hashmap的长度，优化hash算法**

#### 5 说一下什么是缓存雪崩？

> **问题 ：redis的大量数据生存时间到期，导致大量请求访问数据库，导致数据库宕机**
>
> **解决方法：**
>
> * **在缓存预热的时候设置key的生存时间在一个范围，而不是都一样**
> * **查询数据库之前加锁**

#### 6 说一下什么是缓存倾斜？

> **问题：一个超级热点数据存储在redis集群的一个节点上，导致大量的请求都访问这一个节点，然后宕机**
>
> **解决方法：**
>
> * **给存放热点数据的节点搭建主从架构分担压力**
> * **将热点数据存储到jvm缓存中，设置几秒甚至几毫秒的生存时间**
> * **将热点数据信息页面搞成静态资源，每隔一段时间更新下**

#### 7 双写一致性？

> **什么是双写一致性？：双写一致性就是redis和数据库的数据不一致，**
>
> **解决问题：**
>
> * **延迟双删：线程A在修改数据库数据之前先删除Redis的数据，如果这个时候有人查询的话Redis没有就到mysql查询修改前的数据然后放入redis，当A修改完成之后，等待一段时间后，再次删除Redis的缓存,这样可以保证数据一定是一致的，但是会存在一个** `窗口时间`

#### 8 Redis生存时间问题？

> * `定期删除`：Redis每隔一段时间检查几个key查看是否过期
> * `惰性删除`：当我们去查询一个key的时候，redis会先看key的生存时间，如果过期则直接删除

#### 9  Redis淘汰机制？

> **淘汰机制就是内存如果满了，再添加一个新的数据，就会执行淘汰机制。**
>
> **1 **`volatile-lru`
>
> **内存不足时候，从设置了生存时间的key中 干掉最近最少使用的**
>
> **2 **`allkeys-lru`
>
> **内存不足时候，在全部的 key中干掉最近最少使用的**
>
> **3 **`volatile-lfu`
>
> **内存不足时候，从设置了生存时间的key 中 干掉最近最少频次使用的  # 算法与1不同**
>
> **4 **`allkeys-lfu`
>
> **内存不足时候，在全部的key 中 干掉最近最少频次使用的  **
>
> **5 **`volatile-random`
>
> **内存不足时候，从设置了生存时间的key 中 随机干掉一个**
>
> **6** `allkeys-random`
>
> **内存不足时候，在全部的key 中 随机干掉一个**
>
> **7 **`volatile-ttl`
>
> **内存不足时候，从设置了生存时间的key 中 干掉剩余生存时间最少的一个**
>
> **8 **`noeviction(默认)`
>
> **内存不足时候，直接报错**

#### 10 Redis的线程模型？

> **多路复用IO（epoll） ----  FIFO队列    ----    文件事件分排器**

#### 11 Redis集群如何搭？

> **redis集群如果对每个节点做主从，至少需要6个redis，然后**
>
> **集群的特点:**
>
> 1. **对放入的key做crc16运算，对结果对16384除然后取余，得到一个0-16384的值，然后每个节点分别对应一部分。**
> 2. **如果一个节点崩溃，**

## 十 rabbitmq

#### 1 RabbitMQ的作用？

> **解耦，异步，削峰。**

#### 2 RabbitMQ的架构？

> **Connection，Channel，Exchange，Queue**

#### 3 四种交换机？

> * `Direct exchange---直接类型交换机`：要求消息带的路由键和绑定的路由键**完全**匹配，这是一个完整的匹配。
> * `Fanout Exchange---扇出类型交换机`：该类型的交换机绑定队列时可以不指定路由键(**Routingkey**)**当消息发送给该交换机后，它会将消息投递给与该交换机绑定的所有队列**，很像广播，每台子网内的机器都会获得一份消息。
> * `Topic Exchange---主题类型交换机`：将路由键和某模式进行匹配。此时队列需要绑定某一个模式上。符号#匹配0个或多个单词，符号 *匹配一个单词。
> * `Headers Exchanges`：忽略

#### 4 rabbitmq保证消息的可靠性策略有哪些？

> * **消息的持久化机制：保证消息在队列中的时候，如果宕机，再次重启队列中的数据还会存在，可以设置消息的属性的** `deliveryMode`=2，表示消息持久化
> * **手动ack：保证消息一定能被消费者消费，当消费者代码全部执行完成才进行手动ack。**
> * **confirm机制：保证消息一定会发送到交换机。在rabbitmq中保证消息一定会发送到交换机有事务和confirm，因为事务会使效率降低，所以一般都使用的confirm，并且是异步的confirm**
> * **return机制：如果消息从交换机到队列的中间出现问题，会触发对应的回调函数。**

## 算法

#### 1 快排

```
 public void quickSort(int[] array,int left,int right){
     //出口
     if(left>right){
         return;
     }
     int l = left;r=right;
     int base = array[left];
     //循环
     while(l<r){
         while(array[r]>=base&&r>l){
             r--;
         }
         while(array[l]<=base&&l<r){
             l++;
         }
         int temp = array[l];
         array[l]=array[r];
         array[r]=temp;
     }
     //指针相遇,交换与base的值
     array[left] = array[l];
     array[l] = base;
     //递归
     quickSort(array,left,l-1);
     quickSort(array,r+1,right);
 }
```

#### 2 求最大公约数

* **更相减损术**

```
 
```

* **辗转相除法**

```
 
```

* **试商**

```
 
```

#### 3 不创建变量交换

> **a = a^b**
>
> **b = a^b**
>
> **a = a^b**
>
> **或者**
>
> **a = a+b**
>
> **b = a-b**
>
> **a = a-b**

‍
